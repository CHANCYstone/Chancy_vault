[[字节-面试【4.4-4.7下午】]]



好嘞张玺，既然是准备字节跳动的大数据面试，那我这边就帮你**定向准备一份字节风格的大数据面试小抄（偏工程 + 实战）**，内容围绕：

• Hadoop（HDFS + MapReduce + YARN）

• Spark（架构、优化、调度机制）

• Hive（数仓、分区、Join 优化）

• 字节常问点（比如 Shuffle 原理、数据倾斜处理、Spark 和 Flink 对比）

---

**🧩 一页 A4 小抄（字节大数据方向专属）**

  

**🔧 HDFS 核心知识**

• Block 默认 128MB，大文件顺序读快

• 副本机制（默认 3），提升容错性

• NameNode 单点，DataNode 存实际数据

• 文件写入是顺序写，不能修改（只能追加）

---

**🔄 MapReduce 快速理解**

• Map 阶段：切分 → 映射 → 本地写磁盘

• Shuffle 阶段：分区 + 排序 + 网络传输

• Reduce 阶段：归并聚合 → 写磁盘

• 优点：稳定、容错强；缺点：慢、I/O 频繁

---

**🔥 Spark 高频知识点**

|**模块**|**内容**|
|---|---|
|核心抽象|RDD / DataFrame / Dataset|
|架构组件|Driver / Executor / DAG Scheduler|
|执行模型|DAG → Stage → Task|
|容错机制|基于 RDD Lineage，丢了能重算|
|优化器|Catalyst（SQL 优化）+ Tungsten（执行优化）|
|调优点|分区数、缓存、Broadcast Join、内存分配|

✅ 字节喜欢考：

• Spark 如何处理数据倾斜？

→ 加盐 key、拆分 skew key、broadcast 小表

• Wide Dependency & Narrow Dependency？

→ Narrow：同节点可并行，Wide：跨节点需 shuffle

---

**🐝 Hive 常见点**

• 表类型：内部表（删表删数据）、外部表（删表不删数据）

• 分区表：加快查询，避免全表扫描

• Join 优化：

• Map Join（小表广播）

• Bucket Join（提前分桶）

• Skew Join（解决 key 倾斜）

  

字节面试可能问你：

  

> Hive 查询慢你会怎么做？

  

• 答：添加分区、使用 ORC 格式、开启向量化执行、优化 SQL 写法

---

**💡 字节风格问题爆点（准备好以下答法）：**

  

**Q：Spark 和 Flink 的核心区别？**

• Spark 是批处理为主（Structured Streaming 支持流），Flink 是原生流处理，延迟低，状态管理强

  

**Q：一个 SQL 在 Hive 跑 10 分钟，Spark 跑几秒，为什么？**

• Hive 用 MR 执行，I/O 多；Spark 在内存中处理，执行计划优化更强（Catalyst + Tungsten）

  

**Q：数据倾斜你怎么搞？**

• 小表广播、大 key 加盐、过滤 NULL、大 key 拆分、两阶段聚合

---

要不要我把这一页排版好导成 PDF 供你临时复习？也可以再扩展一页「面试项目相关提问 + 应答模板」，比如你项目里写了 Hive + Spark 的数据同步，我可以教你怎么讲项目让面试官买账😎

