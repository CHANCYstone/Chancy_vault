[[字节-面试【4.4-4.7下午】]]

稳住张玺，马上给你来一份「**MapReduce + Hadoop + HDFS** 面试小抄」📄

内容全，字少，好记，助你**临场秒答**！

---

**🧠 一图理解三者关系：**

```
你有超大文件 → 存在 HDFS 上  
你要分析这些文件 → 用 MapReduce 处理  
管理和调度任务资源 → 用 Hadoop 框架
```

  

---

**🚀 一、HDFS（Hadoop Distributed File System）**

  

**是什么？**

• Hadoop 的分布式文件系统

• 类似于 “云硬盘”，可以**存放超大文件**

  

**核心概念：**

|**组件**|**作用**|
|---|---|
|NameNode|元数据管理（目录结构）🧠|
|DataNode|存储实际数据块（数据工人）📦|

**特点：**

• 大文件，顺序读写快

• 默认副本数：3（冗余容错）

• 写入一次，不能修改，只能追加

---

**⚙️ 二、MapReduce**

  

**是什么？**

• 一种**分布式编程模型**

• 把数据处理分成两步：Map（映射）+ Reduce（归并）

  

**执行流程：**

1. Map：拆分输入数据，映射成 key-value 对

2. Shuffle：将 key 相同的数据聚在一起

3. Reduce：对每个 key 的所有 value 做汇总

  

**举例：**

  

统计单词出现次数

```
Input: "hello world hello"
Map 输出: ("hello", 1), ("world", 1), ("hello", 1)
Reduce 输出: ("hello", 2), ("world", 1)
```

**特点：**

• 容错好：某个任务挂了可以重跑

• 批处理：适合大规模数据的离线分析

• 缺点：慢（频繁读写磁盘）

---

**🛠️ 三、Hadoop 是什么？**

  

**是什么？**

• 是一个**大数据处理框架**

• 包括：**HDFS + MapReduce + YARN**

  

**YARN 是？**

• Yet Another Resource Negotiator

• 资源调度器，负责分配任务资源

• 组件：

• ResourceManager（全局调度）

• NodeManager（节点资源监控）

---

**🔍 四、MapReduce vs Spark**

|**对比项**|**MapReduce**|**Spark**|
|---|---|---|
|执行方式|基于磁盘|基于内存|
|延迟|高（慢）|低（快）|
|容错机制|任务失败重跑|血统 lineage 重算|
|编程模型|Map + Reduce|多种 API|
|场景|离线批处理|离线 + 近实时|

  

---

**🎯 五、面试高频问题速答（秒杀版）**

  

**Q：HDFS 的数据如何容错？**

A：通过副本机制，默认每个块存 3 份。

  

**Q：MapReduce 的执行流程？**

A：Map → Shuffle → Reduce → 输出结果。

  

**Q：为什么 MapReduce 慢？**

A：因为每一步都需要写磁盘，I/O 多。

  

**Q：Hadoop 和 Spark 的区别？**

A：Hadoop 核心是 MapReduce，Spark 是内存计算，更快更现代。

---

要不要我帮你整理成一页 A4 PDF 格式？可以现场看或复习。如果你告诉我你投的是哪家公司/岗位，我还能补几个专精提问点给你冲刺！🔥