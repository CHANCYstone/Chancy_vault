1.引入MCMC算法原因——计算高维度积分必须，后验分布计算，很多贝叶斯估计量是基于后验分布
2.介绍MCMC算法，是一种抽样方法，不光适用与贝叶斯
3.其中最常用的一种是们可以使用MCMC方法，尤其是Gibbs采样器，来近似后验分布。简单介绍一下Gibbs抽样
4.使用MCMC算法中的要点
	- 1样本不独立，需要抽样到稳定、收敛状态
		-  马尔可夫链蒙特卡洛（MCMC）-通过运行一个构造得到的马尔可夫链来绘制样本，使其极限（稳态）分布是所关注的联合分布——在不能直接抽样（或者抽样不具备计算效率）时使用——样本不是独立的！
	- 2.MCMC方法不依赖于分布的具体形式，它的通用性确保了其在贝叶斯统计分析、概率模型估计等广泛的统计推断问题中的应用（Tierney, 1994）。
	- 不过Monte Carlo 强调的独立样本在后验分布中难以实现，因而用MarkovChain 抽取与独立样本作用相同的样本，即通过足够多次的重复抽样，其MarkovChain 最终收敛到稳定的后验分布；为了产生具有马氏性、平稳性、正常返性、非周期性、遍历性和不可约性的Markov Chain，目前常用的有两种抽样方法，GibbsSampling 和 Metropolis-Hasting Sampling。
	- 针对MCMC收敛性的改进，文献中提出了多种策略。选择接近目标分布的初始点可以有效减少所需的迭代次数，从而加速收敛过程（Gelman & Rubin, 1992）。适当调整算法参数，如提议分布的方差，也被证明能够改善探索效率和收敛速度（Roberts & Rosenthal, 2009）。此外，采用如Hamiltonian Monte Carlo (HMC) 等更高级的MCMC变体，已被证明可以在处理复杂参数估计问题时提高效率（Neal, 2011）。
	- 此外，MCMC方法的样本效率性也是其受到青睐的一个重要原因。与传统抽样方法相比，MCMC不需要依赖大量的独立同分布样本，这在样本稀缺或数据获取成本较高的实际应用场景中尤为重要（Carlin & Louis, 2008）。然而，MCMC方法的收敛性问题一直是研究者关注的焦点。确保马尔可夫链达到其平稳分布，以便从该链抽样得到的样本能真实反映目标概率分布的特性，是使用MCMC方法时必须考虑的问题（Brooks & Gelman, 1998）。
	- - 假设马氏链迭代 M 次，放弃前 m 次结果 (叫 Burn-in，因为前面的迭代样本不稳定)，把后 面 (M − m) 次结果作为后验分布的样本
5.



贝叶斯方法通常使用马尔可夫链蒙特卡洛（MCMC），而频率主义案例中则使用最大似然（ML）和受限最大似然（REML）。

此外，贝叶斯估计涉及使用频率主义方法中不存在的先验分布信息。然而，比起显而易见的方法论差异，贝叶斯分析框架涉及到与基于似然的文献传统观点非常不同的观点，特别是关于参数性质的观点。

具体来说，频率主义方法使用仅使用样本数据获得的单个值来估计群体参数。相比之下，在贝叶斯范式中，群体参数被估计为一系列值的分布，而不是一个单一的数字。此外，这种估计是通过研究人员提供的先验分布信息和样本数据一起进行的。贝叶斯方法将覆盖参数分布性质的先验信息与从样本数据中获取的信息相结合，以估计后验分布。

在实践中，当对诸如将一个回归系数连接依赖和独立变量的模型的单个值估计时，后验分布的均值、中位数或众数被计算。此外，模型参数的标准差和密度区间也可以从这个后验分布中估计出来。

- 原因：引入MCMC算法原因——计算高维度积分必须
	- A computing revolution based on Markov chain Monte Carlo (MCMC) methods, and the availability of much faster (personal) computers, have together made the Bayesian ﬁtting of multilevel models increasingly easier since the early 1990s. 
	- 后验分布的计算通常是非常棘手且计算密集的。我们可以使用MCMC方法，尤其是Gibbs采样器，来近似后验分布。Gibbs采样器（参见第12章）生成的马尔可夫链的稳态分布即是目标后验分布。在许多情况下，随着WinBUGS等贝叶斯软件的出现，贝叶斯计算变得相对简单，该软件基于BUGS（贝叶斯推断使用Gibbs采样）项目。
	- 在过去几十年中，由于现代计算机和MCMC方法等计算工具的突破，贝叶斯方法有了广泛的发展，基本的贝叶斯推断思想如下：•假设模型中未知参数的一些先验分布；•基于给定数据的参数的后验分布进行推断。后验分布的计算通常具有挑战性，但现在可以使用Gibbs采样等MCMC方法来进行。Gelman等人（2003）对现代贝叶斯方法进行了全面的概述。
	- 通常，计算是贝叶斯推断的主要挑战。然而，由于现代计算机和计算工具（如马尔可夫链蒙特卡罗方法）的可用性，贝叶斯推断对于许多问题变得可行，甚至是直接的。
	- 贝叶斯参数估计理论基于后验分布，由于在通过贝叶斯公式获取未知参数后验分布的过程中需要计算一系列与分布相关的统计量，这个时候往往涉及到高维度积分， 因此计算问题一直是阻碍贝叶斯统计发展的最大障碍。近二十年来，随着计算能力的爆炸性提升以及1990 年代发展起来的MCMC算法（Gelfand 和 Smith 1990；Gilks 1996），使得那些难以直接求解或缺乏数值解的统计模型变得灵活且计算可行。
	- 结合观测数据和研究者选择的先验分布两者信息获得未知参数的后验分布是贝叶斯参数估计核心任务，通常情况下，估计会涉及对后验分布相关的统计量进行计算，比如后验分布的均值和方差常常是关注的统计量。然而由于这些统计量的计算涉及到求解复杂积分，尤其是高维度积分
	- 这些统计量的计算涉及到求解复杂积分，尤其是高维度积分。可以利用抽样方法来近似感兴趣的积分。（说复杂积分不好计算）
	- 贝叶斯方法的广泛应用在很大程度上归因于马尔可夫链蒙特卡罗（MCMC）算法的发展（Gelfand和Smith，1990；Gilks等，1996；Neal，2011），这些算法从统计模型的后验分布中抽取了重复的参数样本，包括复杂模型（例如具有多个或嵌套随机效应的模型）。通过MCMC的抽样参数估计提供了参数的完整后验密度，因此任何明显的非正态性都是显而易见的，可以从MCMC样本中评估参数或区间估计的假设，而不需要基于许多频率学检验的渐近正态性假设。
- 简单介绍MCMC算法
	- - Gelfand和Smith（1990）发表的论文描述了使用MCMC模拟方法总结贝叶斯后验分布，这是将MCMC方法推向统计学热潮的分水岭事件。紧随其后的是Gelman等人（1995年）的书籍《贝叶斯数据分析》和Gilks等人（1996年）的书籍《实践中的马尔可夫链蒙特卡罗》，这两本书将贝叶斯方法和MCMC方法应用于贝叶斯统计模型，直接推进了统计学的主流。我认为这些书在该领域是经典之作，并在本书中大量借鉴了它们。
	- 通过从后验密度中重复抽样进行贝叶斯估计有助于对复杂数据进行建模，随机效应被视为未知量，而不是像频率学方法中有时那样被积分掉（Davidian和Giltinan，2003）。
	- MCMC算法是一类通过迭代方法和某些较简单的提议分布从复杂概率分布中抽样的算法。通过使用先前的样本值来随机生成下一个样本值来构造马尔科夫链。经过大量步骤后，链的状态就被用作来自所需分布的样本。
	- MCMC算法是贝叶斯统计中最常用的参数估计方法，但它本身并不是贝叶斯统计所特有的算法。它是从复杂的抽样分布中按照某些规则和某种分布对参数进行重复抽样的方法，比如在复杂的多层线性模型中抽取后验分布。
	- MCMC方法能够有效地在任意复杂度的概率分布中进行抽样，这一特性使得它成为贝叶斯后验分布估计过程中不可或缺的工具（Gilks et al., 1996）。
	- 贝叶斯方法参数估计依赖于采用某种抽样方法，常用的是Gibbs Sampling 和Metropolis—Hasting法，按照某些规则和某种分布对参数进行重复抽样；当抽样执行足够多次数后，得到收敛的Markov Chain，即抽样点亦收敛为稳定的分布，即后验分布，通过后验的贝叶斯估计，来获取后验未知参数的特征。综上所述，后验分布和参数估计结果的稳健性取决于MCMC是否收敛。
		- 马尔可夫链蒙特卡洛 (MCMC) 法：The Gibbs Sampler 和The Metropolis-Hastings Algorithm。1. The Gibbs Sampler (Geman and Geman, 1984; Gelfand and Smith, 1990; fundamentally changed Bayesian computing ) 2. The Metropolis-Hastings Algorithm (Hastings (1970))
- 使用MCMC算法中的要点
	- 1样本不独立，需要抽样到稳定、收敛状态
		-  马尔可夫链蒙特卡洛（MCMC）-通过运行一个构造得到的马尔可夫链来绘制样本，使其极限（稳态）分布是所关注的联合分布——在不能直接抽样（或者抽样不具备计算效率）时使用——样本不是独立的！
	- 2.MCMC方法不依赖于分布的具体形式，它的通用性确保了其在贝叶斯统计分析、概率模型估计等广泛的统计推断问题中的应用（Tierney, 1994）。
	- 不过Monte Carlo 强调的独立样本在后验分布中难以实现，因而用MarkovChain 抽取与独立样本作用相同的样本，即通过足够多次的重复抽样，其MarkovChain 最终收敛到稳定的后验分布；为了产生具有马氏性、平稳性、正常返性、非周期性、遍历性和不可约性的Markov Chain，目前常用的有两种抽样方法，GibbsSampling 和 Metropolis-Hasting Sampling。
	- 针对MCMC收敛性的改进，文献中提出了多种策略。选择接近目标分布的初始点可以有效减少所需的迭代次数，从而加速收敛过程（Gelman & Rubin, 1992）。适当调整算法参数，如提议分布的方差，也被证明能够改善探索效率和收敛速度（Roberts & Rosenthal, 2009）。此外，采用如Hamiltonian Monte Carlo (HMC) 等更高级的MCMC变体，已被证明可以在处理复杂参数估计问题时提高效率（Neal, 2011）。
	- 此外，MCMC方法的样本效率性也是其受到青睐的一个重要原因。与传统抽样方法相比，MCMC不需要依赖大量的独立同分布样本，这在样本稀缺或数据获取成本较高的实际应用场景中尤为重要（Carlin & Louis, 2008）。然而，MCMC方法的收敛性问题一直是研究者关注的焦点。确保马尔可夫链达到其平稳分布，以便从该链抽样得到的样本能真实反映目标概率分布的特性，是使用MCMC方法时必须考虑的问题（Brooks & Gelman, 1998）。
	- - 假设马氏链迭代 M 次，放弃前 m 次结果 (叫 Burn-in，因为前面的迭代样本不稳定)，把后 面 (M − m) 次结果作为后验分布的样本
- 实施任何MCMC算法时存在两个主要问题：收敛性和混合性。我们必须确保算法产生的马尔可夫链“收敛”到适当的密度（后验密度），并且在整个密度的支持范围内“混合”良好。与用于找到最大似然估计的程序不同，后者收敛到一个点，MCMC算法必须收敛到一个密度，并且在达到收敛后必须“在密度中移动”，在算法运行结束之前从密度的所有区域中抽样，如预期的那样。
	- 收敛性和混合性可能受到许多因素的影响，尤其包括以下几点：
	- 参数的起始值。
		- 与最大似然估计算法一样，起始值可能会影响 MCMC 算法的性能。虽然 MCMC 理论表明，MCMC 算法将在极限下收敛到感兴趣的后验分布，但并不能保证在有限长度的任何运行中都会如此（有关与 MCMC 方法相关的理论讨论，请参见 Tierney 1996；有关更广泛的理论阐述，请参见 Bremaud 1999）。例如，如果一个 MCMC 算法需要 10,000 次迭代才能收敛，但该算法只运行了 1,000 次迭代，那么该算法肯定不会收敛。此外，该算法显然也不会混合得很好。简而言之，如果起始值特别糟糕（例如，远离目标分布的中心），则在达到收敛之前甚至在算法从目标分布中彻底取样之前，运行可能会结束。在某些情况下，特别糟糕的起始值可能会导致算法根本无法“起步”。
			- 解决起始值糟糕的问题的一个明显解决方案是找到更好的起始值！这可能说起来容易，做起来难；然而，对于社会科学中常见的大多数模型，我们通常可以使用类似模型的最大似然估计作为起始值。例如，在本书后面讨论的多元 probit 模型中，我们可以使用单变量 probit 模型的最大似然估计作为起始值。
			- 解决问题的第二种方法可能是运行更多的迭代。在极限下，算法应该收敛到目标分布。
	- 后验分布的形状。
		- 后验分布的形状也可能影响收敛性和混合性。例如，如果后验是多峰的，那么 MCMC 算法可能会迅速收敛到一个模式，但可能在模式之间混合得不好。解决这个问题的方法有很多（有些比其他的更复杂）；一个简单的方法可能是扩展提议密度的宽度/方差，以便从一个模式跳到另一个模式。第二种解决方法可能是找到一个更好的模型，即，加入更好的预测变量（假设模型是回归模型）。多模性的一个原因可能是遗漏了一个重要变量（比如性别）。从理论上讲，后验分布倾向于渐近正态，而对于本书中讨论的模型，如果包含了大部分或所有相关变量，多模性可能很少是一个问题。
		- 然而，MCMC方法在实践中可能表现出收敛速度较慢的特点，一些MCMC方法（例如哈密尔顿蒙特卡罗）的实现具有一些优势的估计特征，包括更快的收敛速度，已通过R中的包开发（rstan）得到改进。
	- 通过MCMC技术对层次和随机效应模型进行贝叶斯建模已经扩展了现代数据分析的范围。尽管如此，应用贝叶斯技术也引发了一些特定问题，尽管这些问题已经得到了缓解，例如综合嵌套拉普拉斯近似（Rue等，2009）和实际实现的哈密尔顿蒙特卡罗（Carpenter等，2017）。这些问题包括：a）当将模糊先验应用于随机效应的方差或离散参数时的适用性和可辨识性问题（Hobert和Casella，1996；Palmer和Pettit，1996；Hadjicostas和Berry，1999；Yue等，2012）；b）为方差参数选择最适合的先验形式（Gelman，2006）或最适合的协方差建模先验（Lewandowski等，2009）；c）对于具有随机效应的模型，适当的先验，以避免在空间应用中出现真正异常值时过度拟合（Simpson等，2017；Fuglstad等，2018）或过度平滑（Conlon和Louis，1999）；d）在存在一系列可能的模型结构的复杂数据结构的分层模型中，存在规范偏差的可能性（Chiang等，1999）。
	- 在 MH 算法中的提议密度的选择。
-   
在实践中，MCMC方法通常分别应用于单个参数或多个参数块（Roberts和Sahu，1997）。因此，假设 θ 包含多个参数，并由 C 个组成或块 {θ1, θ2, ..., θC}，可以为每个组件使用不同的更新方法，包括块更新。 









GibbsSampling是Metropolis-Hastings算法的一个特例。当从多元后验中抽样不可行时，可以使用吉布斯抽样器，但可以从单变量条件分布中抽样。
条件后验分布通常比联合后验具有更简单的结构，因此更容易从中抽样。
GibbsSampling的基本思想是通过反复从每个参数的单变量分布中抽样，条件于其他参数的当前值，可以从多维后验分布中抽样。对于参数向量和观察数据，通过以下步骤构建吉布斯抽样器可以获得联合后验分布的样本：

任何MCMC抽样器成功实现的关键问题是链收敛所需的迭代次数。通常，首先一组迭代被丢弃（称为燃烧期），因为初始样本受到任意起始值的影响。通过选择合理的初始值，可以缩短燃烧期的长度。

对于剩余的迭代，可以使用各种检查来评估是否确实已经达到收敛。通过视觉检查抽样值的图表，特别是如果比较了具有不同起始值的几个链，可以对所需燃烧期的长度和抽样的收敛性获得良好的印象。此外，还可以计算形式诊断，例如Rˆ（Gelman & Rubin, 1992），该诊断评估链间和链内变异以获取有关MCMC样本收敛的信息。有关收敛诊断的更详细的介绍和讨论，请参阅Cowles和Carlin（1996）。

燃烧期之后的剩余迭代构成了对预期后验分布的样本。可以对这些样本应用离散公式来总结关于参数的（后验）知识。例如，参数θq的分布的均值可以通过θ(h)的样本值的平均值来估计。类似地，可以计算后验标准差和各种分位数（例如，95％置信区间）。


MCMC是一个迭代过程，在该过程中，先验分布与来自实际样本的信息结合，用于估计每个模型参数的后验分布（例如，回归系数、随机效应方差）。从这个后验分布中，参数值被模拟大量次数，以获得一个估计的后验分布。在每次绘制这样的样本后，后验分布都会更新。这个迭代的抽样和更新过程重复多次（例如，10,000次或更多次），直到研究者看到后验分布收敛的证据，即从一个抽样得到的值与上一个抽样得到的值非常相似。MCMC中的Markov链部分反映了从后验分布中抽取当前值的过程，给定了先前抽样值。蒙特卡洛部分反映了从后验分布中对这些值进行随机模拟。在值链收敛之后，我们得到了感兴趣参数（例如，回归系数）的后验分布的估计。在这一点上，可以通过从后验分布中计算均值、中值或众数来获得单一的模型参数估计。

在使用MCMC时，研究者必须注意一些估计的技术方面，以确保分析正常运行。收集到的10,000（或更多）个单独的参数估计形成了一个漫长的时间序列，必须对其进行检查，以确保两个事实是正确的。首先，参数估计必须收敛，其次，过程中不同迭代之间的自相关性应该很低。参数的收敛可以通过轨迹图进行评估，轨迹图就是将参数估计按照从第一次迭代到最后一次迭代的顺序绘制成的图表。估计值的自相关性是针对各种迭代计算的，研究者将寻找在这些估计值之间的距离，自相关性变得相当低的位置。

当研究者确定估计之间的自相关性降低到足够低的程度时，就会对估计进行稀疏化，以去除那些可能相互高度自相关的估计。例如，如果估计之间的自相关性在相隔10个迭代时很低，那么10,000个样本点的时间序列将被稀疏化，只包括每隔十个观察值，以创建参数的后验分布。然后，仅使用稀疏化后的值来计算该分布的平均值、中位数和众数，以得到 R 报告的单一参数估计值。最后一个问题是所谓的“烧掉期”。关于分布的收敛，研究者不希望在时间序列收敛之前的迭代中包括任何值到后验分布中。因此，收敛之前的迭代被称为发生在“烧掉期”，不用于计算后验均值、中位数和众数。在 R 中，用户可以设置每个 MCMC 条件（迭代次数、稀疏化率和烧掉期）或使用默认值。本章的其余部分将提供 MCMC 结果诊断的详细示例，以及设置 MCMC 参数和先验分布。


转而依赖 MCMC 来推导模型参数的后验分布。然而，更基本的是，贝叶斯统计在估计总体参数的方式上与基于似然的频率统计有根本性的不同。在频率主义方法中，它们取单个值。

贝叶斯统计将总体参数估计为分布，因此参数的基于样本的估计是使用 MCMC 获得的后验分布，而不是从样本计算出的单个值。

除了本章描述的方法与前面章节中描述的方法之间的更多理论差异外，应用中也存在非常真实的差异。使用贝叶斯统计的分析人员处理的是一个在许多方面更加灵活的建模范式，它不依赖于必须满足最大似然成功使用的标准假设，比如正态性。与此同时，这种更大的灵活性是以更复杂的模型估计为代价的。从实践的角度来看，比较本章中所展示的分析与第三章中描述的分析有多少不同。此外，贝叶斯建模结果的解释需要分析人员在确保模型收敛、决定链的长度和所需的稀疏度、以及确定要用于提供单个参数估计的后验分布的摘要统计量方面付出更多的精力。最后但同样重要的是，分析人员必须考虑模型参数的先验分布应该是什么，知道特别是对于小样本，选择将直接影响最终参数估计的先验会有重要影响。

尽管贝叶斯建模带来了许多复杂性，但同样也可以说，这样的模型为细心和知情的研究人员提供了一套非常灵活和强大的工具。特别是，正如本章开头所指出的，贝叶斯分析包括多层模型在模型形式上提供了更大的灵活性，不需要分布假设，而且对于较小的样本可能特别有用。因此，我们可以毫不保留地推荐这种方法，即使感兴趣的研究人员需要投入更多的时间和精力来决定先验，确定模型何时是否收敛，并选择最适合的后验分布摘要统计量。那些愿意投入时间和精力的人将有可能生成非常有用和灵活的模型，这些模型可能在标准的基于似然的方法无法胜任的情况下发挥作用。




- 
	- 
- 
	- 用计算机模拟产生后验分布的大量样本，用以计算后验分布及其特征。
	- 1. 计算机模拟简介 (a) 模拟法计算函数的积分 (b) 随机变量分布的直接模拟法（MC） 
	- 2. 马尔可夫链蒙特卡罗法 (MCMC) (a) The Metropolis-Hastings Algorithm（MH 迭代法） (b) The Gibbs Sampler（吉布斯抽样器）
	
	- (a) Gibbs Sampler • 对所有边缘条件后验分布依次抽样 • 简单 (b) Metropolis-Hastings • 选取合适的预选分布作为马氏链的转移分布 • Gibbs 是 MH 的特例
	- [Ch5_h.pdf (rbind.io)](https://andrewwang.rbind.io/courses/bayesian_statistics/notes/Ch5_h.pdf)



- 图2——图5分别是试验组和对照组脏器损伤（Moj）和安全性指标各次随访均值（θj）组间差异的 Gelman-Plot和ACF plot，来判断Iteration和Burn-in次数是否 足够，Thinning大小是否需要调整。
- Gelman-Plot 是在诊断收敛的“Gelman-Rubin”的方法衍生而来，用于判断 MCMC的Iteration及Burn-in次数是否足够。Gelman-Rubin 诊断方法利用起始值分散的多条MCMC链收敛后Between-Chain方差接近于Within-Chain方差的特性， 计算的Shrink Factor统计量接近1,97.5百分位应该小于1.2［32］。Gelman-Plot由 于能看到Shrink Factor 随着抽样次数变化的情况，避免Shrink Factor 统计量偶 然出现的误差导致错误的结论。
- ACF plot 基于 Auto-Correlation Function 方法而来，该方法用于计算 MCMC 抽样点在不同Lag之间的相关性。根据MCMC特性每一个抽样点位置只与上一个抽样点位置相关，与其余抽样点无关，基于此ACF plot 画出在不同Lag时抽样点相关性图，若Lag＞2而相关性大于0.5可认为抽样点独立性不够，可通过调节Thinning 大小缓解，并对MCMC链是否收敛能给予一定的参考性意见［33］。
- 图2、图3显示试验组和对照组各次随访时脏器损伤差异（Moj）和安全性指标均值差异（θ）的Shrink Factor，均一直都保持在1.2以内；因此说明MCMC已经收敛，Iteration和Burin次数足够；图4，图5是上述参数的Auto correlation， 当lag＝0时较大，其余较小接近于0，表明MCMC抽样点相互独立，Thinning
大 小为1正好，间接说明MCMC已收敛。








